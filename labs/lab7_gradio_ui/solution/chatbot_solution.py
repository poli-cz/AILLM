import gradio as gr
import json
import textwrap
import os, sys

# P≈ôidej cestu d≈ô√≠v, ne≈æ zaƒçne≈° importovat vlastn√≠ soubory
sys.path.append(
    os.path.abspath(os.path.join(os.path.dirname(__file__), "../../common"))
)

from langchain_community.llms import Ollama
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationalRetrievalChain
from faiss_utils import load_faiss


# --- Stav / inicializace -----------------------------------------------------


def build_chain(k: int = 3, temperature: float = 0.7, max_tokens: int = 512):
    # LLM: temperature + max_tokens po≈°leme p≈ôes model_kwargs
    llm = Ollama(
        model="mistral",
        model_kwargs={
            "temperature": float(temperature),
            "num_predict": int(max_tokens),
        },
    )
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    store = load_faiss()  # m≈Ø≈æe vyhodit chybu, o≈°et≈ô√≠me v UI
    retriever = store.as_retriever(search_type="mmr", search_kwargs={"k": int(k)})
    chain = ConversationalRetrievalChain.from_llm(
        llm, retriever=retriever, memory=memory, return_source_documents=True
    )
    return chain, memory


# form√°tov√°n√≠ citac√≠ z n√°vratov√Ωch dokument≈Ø
def format_citations(source_docs):
    cites = []
    for d in source_docs or []:
        src = d.metadata.get("source", "?")
        cid = d.metadata.get("chunk_id", "?")
        cites.append(f"[{src}#{cid}]")
    return " ".join(cites) if cites else "(bez citac√≠)"


# --- UI logika ---------------------------------------------------------------

with gr.Blocks(title="Lab7 RAG Chatbot") as demo:
    gr.Markdown("## Lab 7 ‚Äì Chatbot s UI (RAG, pamƒõ≈•, citace)")

    with gr.Row():
        with gr.Column(scale=3):
            chat = gr.Chatbot(height=480, label="Chat")
            user_msg = gr.Textbox(
                placeholder="Zadej dotaz‚Ä¶ nebo /reset", show_label=False
            )
            with gr.Row():
                btn_send = gr.Button("Odeslat", variant="primary")
                btn_reset_mem = gr.Button("Reset pamƒõti")
                btn_reload = gr.Button("Reload FAISS")
                btn_export = gr.Button("Export konverzace")
            status = gr.Markdown("", elem_id="status")
        with gr.Column(scale=1):
            gr.Markdown("### Nastaven√≠")
            temperature = gr.Slider(0, 1, value=0.7, step=0.05, label="Temperature")
            max_tokens = gr.Slider(64, 2048, value=512, step=64, label="Max tokens")
            retr_k = gr.Slider(1, 10, value=3, step=1, label="Retriever K")

    # Sd√≠len√© stavy (dr≈æ√°k ≈ôetƒõzce, pamƒõ≈• a posledn√≠ch citac√≠)
    chain_state = gr.State(None)  # ConversationalRetrievalChain
    memory_state = gr.State(None)  # ConversationBufferMemory
    cites_state = gr.State("")  # posledn√≠ citace pro info

    def init_chain(k, temp, max_tok):
        try:
            chain, memory = build_chain(
                k=int(k), temperature=float(temp), max_tokens=int(max_tok)
            )
            return chain, memory, "‚úÖ ≈òetƒõzec inicializov√°n.", ""
        except Exception as e:
            return None, None, f"‚ùå Nepoda≈ôilo se inicializovat ≈ôetƒõzec: {e}", ""

    # init p≈ôi startu
    _ = demo.load(
        fn=init_chain,
        inputs=[retr_k, temperature, max_tokens],
        outputs=[chain_state, memory_state, status, cites_state],
    )

    def respond(user_message, chat_history, k, temp, max_tok, chain, memory):
        if chain is None or memory is None:
            # zkusme znovu init (t≈ôeba po reloadu)
            chain, memory, msg, _ = init_chain(k, temp, max_tok)
            chat_history = chat_history or []
            chat_history.append(("üîÑ Auto-init", msg))
            return "", chat_history, chain, memory, ""

        # p≈ô√≠kaz /reset
        if user_message.strip() == "/reset":
            memory.clear()
            chat_history = []
            return "", chat_history, chain, memory, "üßπ Pamƒõ≈• vymaz√°na."

        try:
            # aktualizovat parametry za bƒõhu (teplota, max_tokens, k)
            chain.llm.model_kwargs.update(
                {"temperature": float(temp), "num_predict": int(max_tok)}
            )
            chain.retriever.search_kwargs["k"] = int(k)

            result = chain.invoke({"question": user_message})
            answer = result.get("answer", "").strip()
            source_docs = result.get("source_documents", [])
            cites = format_citations(source_docs)

            chat_history = chat_history or []
            chat_history.append((user_message, f"{answer}\n\n**Citace:** {cites}"))
            return "", chat_history, chain, memory, ""
        except Exception as e:
            chat_history = chat_history or []
            chat_history.append((user_message, f"‚ùå Chyba: {e}"))
            return "", chat_history, chain, memory, ""

    def reset_memory(memory):
        if memory:
            memory.clear()
        return [], "üßπ Pamƒõ≈• vymaz√°na."

    def reload_index(k, temp, max_tok):
        # znovu postav√≠me cel√Ω ≈ôetƒõzec (nov√Ω retriever nad novƒõ nahran√Ωm indexem)
        chain, memory, msg, _ = init_chain(k, temp, max_tok)
        return chain, memory, f"üîÅ {msg}"

    def export_chat(chat_history):
        try:
            with open("conversation.json", "w", encoding="utf-8") as f:
                json.dump(chat_history or [], f, ensure_ascii=False, indent=2)
            return "üíæ Export hotov ‚Üí conversation.json"
        except Exception as e:
            return f"‚ùå Export selhal: {e}"

    # Dr√°tov√°n√≠ akc√≠
    btn_send.click(
        fn=respond,
        inputs=[
            user_msg,
            chat,
            retr_k,
            temperature,
            max_tokens,
            chain_state,
            memory_state,
        ],
        outputs=[user_msg, chat, chain_state, memory_state, status],
    )
    user_msg.submit(
        fn=respond,
        inputs=[
            user_msg,
            chat,
            retr_k,
            temperature,
            max_tokens,
            chain_state,
            memory_state,
        ],
        outputs=[user_msg, chat, chain_state, memory_state, status],
    )
    btn_reset_mem.click(fn=reset_memory, inputs=[memory_state], outputs=[chat, status])
    btn_reload.click(
        fn=reload_index,
        inputs=[retr_k, temperature, max_tokens],
        outputs=[chain_state, memory_state, status],
    )
    btn_export.click(fn=export_chat, inputs=[chat], outputs=[status])

if __name__ == "__main__":
    demo.launch()
